This repository contains most of the files necessary to run an interactive user interface that facilitates the manual and automated classification of amphibian vocalizations within recordings. The neural network model files are not included due to github size limits; please reach out to gavin.hurd@pc.gc.ca for access. 
Alternatively, custom models can be integrated, provided they are compatible with OpenSoundScape v0.10.0 (PyTorch). 

Overview of user interface:

![](https://github.com/hurdg/amphibian-bioacoustics-user-interface/blob/main/images/UI_annotation1.png) "Features that support navigation through audio recordings."



![](https://github.com/hurdg/amphibian-bioacoustics-user-interface/blob/main/images/UI_annotation2.png)) "Ability for manual and automated classification. Automated classification is based on the neural networks predictions in relation a user-defined threshold value. An upper and lower threshold value can be specified."
